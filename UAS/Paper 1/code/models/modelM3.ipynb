{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelM3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelM3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
    "        self.conv2_bn = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
    "        self.conv4_bn = nn.BatchNorm2d(80)\n",
    "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
    "        self.conv5_bn = nn.BatchNorm2d(96)\n",
    "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
    "        self.conv6_bn = nn.BatchNorm2d(112)\n",
    "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
    "        self.conv7_bn = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
    "        self.conv8_bn = nn.BatchNorm2d(144)\n",
    "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
    "        self.conv9_bn = nn.BatchNorm2d(160)\n",
    "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
    "        self.conv10_bn = nn.BatchNorm2d(176)\n",
    "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
    "        self.fc1_bn = nn.BatchNorm1d(10)\n",
    "    def get_logits(self, x):\n",
    "        x = (x - 0.5) * 2.0\n",
    "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
    "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
    "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
    "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
    "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
    "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
    "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
    "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
    "        logits = self.fc1_bn(self.fc1(flat1))\n",
    "        return logits\n",
    "    def forward(self, x):\n",
    "        logits = self.get_logits(x)\n",
    "        return F.log_softmax(logits, dim=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9523a37af404a38faef25db205912ad6cb8132cdee7866946406cb826ddd44a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
