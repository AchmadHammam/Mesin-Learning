{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import argparse\n",
    "import numpy as np \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from ema import EMA\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training=True, transform=None):\n",
    "        if training==True:\n",
    "            f = open('D:/Python/Mesin Learning/UAS/Paper 1/data/raw/train_images', 'rb')\n",
    "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
    "            f.close()\n",
    "            f = open('D:/Python/Mesin Learning/UAS/Paper 1/data/raw/train_labels', 'rb')\n",
    "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open('D:/Python/Mesin Learning/UAS/Paper 1/data/raw/t10k_images', 'rb')\n",
    "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
    "            f.close()\n",
    "            f = open('D:/Python/Mesin Learning/UAS/Paper 1/data/raw/t10k_labels', 'rb')\n",
    "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
    "            f.close()\n",
    "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
    "        ys = ys.astype(np.int)\n",
    "        self.x_data = xs\n",
    "        self.y_data = ys\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
    "        y = torch.tensor(np.array(self.y_data[idx]))\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        x = transforms.ToTensor()(np.array(x)/255)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelM3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelM3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
    "        self.conv2_bn = nn.BatchNorm2d(48)\n",
    "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
    "        self.conv4_bn = nn.BatchNorm2d(80)\n",
    "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
    "        self.conv5_bn = nn.BatchNorm2d(96)\n",
    "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
    "        self.conv6_bn = nn.BatchNorm2d(112)\n",
    "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
    "        self.conv7_bn = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
    "        self.conv8_bn = nn.BatchNorm2d(144)\n",
    "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
    "        self.conv9_bn = nn.BatchNorm2d(160)\n",
    "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
    "        self.conv10_bn = nn.BatchNorm2d(176)\n",
    "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
    "        self.fc1_bn = nn.BatchNorm1d(10)\n",
    "    def get_logits(self, x):\n",
    "        x = (x - 0.5) * 2.0\n",
    "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
    "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
    "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
    "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
    "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
    "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
    "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
    "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
    "        logits = self.fc1_bn(self.fc1(flat1))\n",
    "        return logits\n",
    "    def forward(self, x):\n",
    "        logits = self.get_logits(x)\n",
    "        return F.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelM5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelM5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
    "        self.conv3_bn = nn.BatchNorm2d(96)\n",
    "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
    "        self.conv4_bn = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
    "        self.conv5_bn = nn.BatchNorm2d(160)\n",
    "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
    "        self.fc1_bn = nn.BatchNorm1d(10)\n",
    "    def get_logits(self, x):\n",
    "        x = (x - 0.5) * 2.0\n",
    "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
    "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
    "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
    "        logits = self.fc1_bn(self.fc1(flat5))\n",
    "        return logits\n",
    "    def forward(self, x):\n",
    "        logits = self.get_logits(x)\n",
    "        return F.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelM7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelM7, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
    "        self.conv1_bn = nn.BatchNorm2d(48)\n",
    "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
    "        self.conv2_bn = nn.BatchNorm2d(96)\n",
    "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
    "        self.conv3_bn = nn.BatchNorm2d(144)\n",
    "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
    "        self.conv4_bn = nn.BatchNorm2d(192)\n",
    "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
    "        self.fc1_bn = nn.BatchNorm1d(10)\n",
    "    def get_logits(self, x):\n",
    "        x = (x - 0.5) * 2.0\n",
    "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
    "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
    "        logits = self.fc1_bn(self.fc1(flat1))\n",
    "        return logits\n",
    "    def forward(self, x):\n",
    "        logits = self.get_logits(x)\n",
    "        return F.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    def __init__(self, degrees, seed=1):\n",
    "        self.degrees = (-degrees, degrees)\n",
    "        random.seed(seed)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        angle = random.uniform(degrees[0], degrees[1])\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        angle = self.get_params(self.degrees)\n",
    "        return F.rotate(img, angle, False, False, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
    "\n",
    "    # enable GPU usage ------------------------------------------------------------#\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda == False:\n",
    "        print(\"WARNING: CPU will be used for training.\")\n",
    "        exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MnistDataset(training=False, transform=None)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_kernel_size=5\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if(p_kernel_size == 3):\n",
    "    model1=ModelM3().to(device)\n",
    "elif(p_kernel_size == 5):\n",
    "    model1=ModelM5().to(device)\n",
    "elif (p_kernel_size == 5) :\n",
    "    model1=ModelM7().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_seed=0\n",
    "p_logdir=\"temp\"\n",
    "model1.eval()\n",
    "test_loss = 0\n",
    "test_loss = test_loss.type(torch.LongTensor)\n",
    "correct = 0\n",
    "wrong_images = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model1(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
    "\n",
    "np.savetxt(\"../logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--logdir\", default=\"modelM5\")\n",
    "    p.add_argument(\"--seed\", default=0, type=int)\n",
    "    p.add_argument(\"--trials\", default=30, type=int)\n",
    "    p.add_argument(\"--kernel_size\", default=5, type=int)\n",
    "    args = p.parse_args()\n",
    "    for i in range(args.trials):\n",
    "        run(p_seed = args.seed + i,\n",
    "            p_kernel_size = args.kernel_size,\n",
    "            p_logdir = args.logdir)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9523a37af404a38faef25db205912ad6cb8132cdee7866946406cb826ddd44a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
